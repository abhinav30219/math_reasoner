{
  "training": {
    "batch_size": 16,
    "num_epochs": 5,
    "gradient_accumulation_steps": 8,
    "learning_rate": 2e-5,
    "weight_decay": 0.01,
    "max_grad_norm": 1.0,
    "log_interval": 10,
    "eval_interval": 100,
    "save_interval": 500,
    "seed": 42,
    "warmup_steps": 100,
    "temperature": 2.0
  },
  "teacher_model": {
    "model_type": "deepseek",
    "model_name_or_path": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "max_length": 2048,
    "precision": "bf16",
    "use_flash_attention": true
  },
  "student_model": {
    "model_type": "qwen",
    "model_name_or_path": "Qwen/Qwen2.5-1.5B",
    "max_length": 2048,
    "precision": "bf16",
    "use_flash_attention": true,
    "use_lora": false
  },
  "loss": {
    "kl_weight": 0.5,
    "ce_weight": 0.5,
    "mse_logits_weight": 0.0,
    "hidden_states_weight": 0.0,
    "response_kl_weight": 0.8
  },
  "dataset": {
    "dataset_paths": ["numina/numina-math-filtered", "openai/openai-r1-math-220k"],
    "probabilities": [0.7, 0.3],
    "max_samples": 500000,
    "problem_prefix": "Problem: ",
    "solution_prefix": "Solution: ",
    "train_split": "train",
    "eval_split": "test",
    "eval_ratio": 0.03
  },
  "output": {
    "output_dir": "models/distill-qwen-1.5b",
    "logging_dir": "logs/distillation",
    "use_wandb": false,
    "wandb_project": "ai-math-reasoning",
    "wandb_run_name": "distill-run"
  },
  "distributed": {
    "use_deepspeed": false,
    "deepspeed_config": "configs/deepspeed/ds_config_zero2.json",
    "use_accelerate": true,
    "gradient_checkpoint": true,
    "ddp_find_unused_parameters": false
  },
  "generation": {
    "temperature": 0.7,
    "top_p": 0.9,
    "max_new_tokens": 1024,
    "num_return_sequences": 1,
    "do_sample": true
  }
}
